{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ast\n",
    "import wfdb\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Helper functions from `example_physionet.py`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_raw_data(df, sampling_rate, path):\n",
    "    \"\"\"\n",
    "    \n",
    "    Load raw signal data based on a specified sampling rate.\n",
    "\n",
    "    This function reads raw data files using a sampling rate to determine the appropriate file set\n",
    "    (low resolution or high resolution) to load. The function returns an array of signals.\n",
    "\n",
    "    Args:\n",
    "        df (DataFrame): A pandas DataFrame containing the file names under columns \n",
    "                        'filename_lr' for low resolution and 'filename_hr' for high resolution.\n",
    "        sampling_rate (int): The sampling rate in Hz. If set to 100, low resolution data files are loaded.\n",
    "        path (str): The file path prefix required to access the data files.\n",
    "\n",
    "    Returns:\n",
    "        numpy.ndarray: An array of signal data extracted from the files.\n",
    "        \n",
    "    \"\"\"\n",
    "    \n",
    "    if sampling_rate == 100:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_lr]\n",
    "    else:\n",
    "        data = [wfdb.rdsamp(path+f) for f in df.filename_hr]\n",
    "    data = np.array([signal for signal, meta in data])\n",
    "    return data\n",
    "\n",
    "\n",
    "def aggregate_diagnostic(y_dic):\n",
    "    \"\"\"\n",
    "    \n",
    "    Aggregate diagnostic classes based on keys from a dictionary that exist in a global DataFrame.\n",
    "\n",
    "    This function iterates over keys in the input dictionary and aggregates diagnostic classes \n",
    "    from a predefined DataFrame `agg_df` where keys match indices. The function returns a list \n",
    "    of unique diagnostic classes.\n",
    "\n",
    "    Args:\n",
    "        y_dic (dict): A dictionary where keys represent some identifiers which are used to look up \n",
    "                      diagnostic classes in a global DataFrame `agg_df`.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of unique diagnostic classes corresponding to the keys in the input dictionary\n",
    "              that are present in `agg_df`.\n",
    "              \n",
    "    \"\"\"\n",
    "    \n",
    "    tmp = []\n",
    "    for key in y_dic.keys():\n",
    "        if key in agg_df.index:\n",
    "            tmp.append(agg_df.loc[key].diagnostic_class)\n",
    "    return list(set(tmp))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = 'data/'\n",
    "sampling_rate = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Optimize the following, loading is pretty slow!  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load and convert annotation data\n",
    "Y = pd.read_csv(path+'ptbxl_database.csv', index_col='ecg_id')\n",
    "Y.scp_codes = Y.scp_codes.apply(lambda x: ast.literal_eval(x))\n",
    "\n",
    "# Load raw signal data\n",
    "X = load_raw_data(Y, sampling_rate, path)\n",
    "\n",
    "# Load scp_statements.csv for diagnostic aggregation\n",
    "agg_df = pd.read_csv(path+'scp_statements.csv', index_col=0)\n",
    "agg_df = agg_df[agg_df.diagnostic == 1]\n",
    "\n",
    "# Apply diagnostic superclass\n",
    "Y['diagnostic_superclass'] = Y.scp_codes.apply(aggregate_diagnostic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split data into train and test\n",
    "test_fold = 10\n",
    "# Train\n",
    "X_train = X[np.where(Y.strat_fold != test_fold)]\n",
    "y_train = Y[(Y.strat_fold != test_fold)].diagnostic_superclass\n",
    "# Test\n",
    "X_test = X[np.where(Y.strat_fold == test_fold)]\n",
    "y_test = Y[Y.strat_fold == test_fold].diagnostic_superclass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(21799, 1000, 12)\n"
     ]
    }
   ],
   "source": [
    "print(X.shape)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py311-ecgsorter",
   "language": "python",
   "name": "py311-ecgsorter"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
